{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import transformers as ppb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_projector', 'vocab_layer_norm', 'activation_13', 'vocab_transform']\n",
      "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# DistilBERT\n",
    "model_class = ppb.TFDistilBertModel\n",
    "tokenizer_class = ppb.DistilBertTokenizer\n",
    "pretrained_weights = 'distilbert-base-uncased'\n",
    "\n",
    "#BERT\n",
    "#model_class = ppb.TFBertModel\n",
    "#tokenizer_class = ppb.BertTokenizer\n",
    "#pretrained_weights = 'bert-base-uncased'\n",
    "\n",
    "\n",
    "model = model_class.from_pretrained(pretrained_weights)\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': <tf.Tensor: shape=(1, 12), dtype=int32, numpy=\n",
       "array([[ 101, 5672, 2033, 2011, 2151, 3793, 2017, 1005, 1040, 2066, 1012,\n",
       "         102]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(1, 12), dtype=int32, numpy=array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)>}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Replace me by any text you'd like.\"\n",
    "\n",
    "encoded_text = tokenizer(text, return_tensors='tf')\n",
    "#encoded_text = tokenizer(text)\n",
    "encoded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[CLS] replace me by any text you'd like. [SEP]\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(encoded_text['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_text['input_ids']\n",
    "output = model(encoded_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 12, 768])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.last_hidden_state.shape # Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'score': 0.08231750130653381,\n",
       "   'token': 2416,\n",
       "   'token_str': 'six',\n",
       "   'sequence': '[CLS] in a year, there are six months in which [MASK] is the first. [SEP]'},\n",
       "  {'score': 0.07331888377666473,\n",
       "   'token': 2176,\n",
       "   'token_str': 'four',\n",
       "   'sequence': '[CLS] in a year, there are four months in which [MASK] is the first. [SEP]'},\n",
       "  {'score': 0.06642419844865799,\n",
       "   'token': 2698,\n",
       "   'token_str': 'seven',\n",
       "   'sequence': '[CLS] in a year, there are seven months in which [MASK] is the first. [SEP]'},\n",
       "  {'score': 0.061364300549030304,\n",
       "   'token': 2093,\n",
       "   'token_str': 'three',\n",
       "   'sequence': '[CLS] in a year, there are three months in which [MASK] is the first. [SEP]'},\n",
       "  {'score': 0.04870373755693436,\n",
       "   'token': 4376,\n",
       "   'token_str': 'twelve',\n",
       "   'sequence': '[CLS] in a year, there are twelve months in which [MASK] is the first. [SEP]'}],\n",
       " [{'score': 0.09364783763885498,\n",
       "   'token': 7114,\n",
       "   'token_str': 'autumn',\n",
       "   'sequence': '[CLS] in a year, there are [MASK] months in which autumn is the first. [SEP]'},\n",
       "  {'score': 0.06499496847391129,\n",
       "   'token': 3500,\n",
       "   'token_str': 'spring',\n",
       "   'sequence': '[CLS] in a year, there are [MASK] months in which spring is the first. [SEP]'},\n",
       "  {'score': 0.06285294145345688,\n",
       "   'token': 10957,\n",
       "   'token_str': 'easter',\n",
       "   'sequence': '[CLS] in a year, there are [MASK] months in which easter is the first. [SEP]'},\n",
       "  {'score': 0.05347507819533348,\n",
       "   'token': 4542,\n",
       "   'token_str': 'rain',\n",
       "   'sequence': '[CLS] in a year, there are [MASK] months in which rain is the first. [SEP]'},\n",
       "  {'score': 0.032838374376297,\n",
       "   'token': 10101,\n",
       "   'token_str': 'rainfall',\n",
       "   'sequence': '[CLS] in a year, there are [MASK] months in which rainfall is the first. [SEP]'}]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = ppb.pipeline\n",
    "unmasker = pipeline('fill-mask', model=pretrained_weights)\n",
    "#unmasker([\"children play in the [MASK].\", \"boy play in the [MASK].\", \"girl play in the [MASK].\"])\n",
    "#unmasker(\"[MASK] Allan Poe.\")\n",
    "unmasker(\"In a year, there are [MASK] months in which [MASK] is the first.\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b08913b4f0455f4a15a2d98d905f8024e1a13ec150e53f8fa46268505401dd78"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 ('venvML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
